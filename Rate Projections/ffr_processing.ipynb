{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14399e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas_datareader.data as web\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc5480f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015.003164</td>\n",
       "      <td>0.105111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.045696</td>\n",
       "      <td>0.120294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015.045696</td>\n",
       "      <td>0.097520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015.088229</td>\n",
       "      <td>0.120294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015.088229</td>\n",
       "      <td>0.097520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "0  2015.003164  0.105111\n",
       "1  2015.045696  0.120294\n",
       "2  2015.045696  0.097520\n",
       "3  2015.088229  0.120294\n",
       "4  2015.088229  0.097520"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick look at one CSV to confirm structure\n",
    "sample_path = sorted(glob.glob('*.csv'))[0]\n",
    "sample_df = pd.read_csv(sample_path, header=None)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "487f9ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHS = {\n",
    "    'JAN': 1, 'FEB': 2, 'MAR': 3, 'APR': 4, 'MAY': 5, 'JUN': 6,\n",
    "    'JUL': 7, 'AUG': 8, 'SEP': 9, 'OCT': 10, 'NOV': 11, 'DEC': 12\n",
    "}\n",
    "\n",
    "def date_to_decimal_year(dt):\n",
    "    start = datetime(dt.year, 1, 1)\n",
    "    end = datetime(dt.year + 1, 1, 1)\n",
    "    return dt.year + (dt - start).total_seconds() / (end - start).total_seconds()\n",
    "\n",
    "def decimal_year_to_date(x):\n",
    "    year = int(np.floor(x))\n",
    "    frac = x - year\n",
    "    start = datetime(year, 1, 1)\n",
    "    end = datetime(year + 1, 1, 1)\n",
    "    return start + (end - start) * frac\n",
    "\n",
    "def parse_forecast_date_from_filename(filename):\n",
    "    base = os.path.basename(filename)\n",
    "    m = re.match(r'^([A-Za-z]{3})(\\d{2})FFR\\.csv$', base)\n",
    "    if not m:\n",
    "        raise ValueError(f'Unrecognized forecast filename: {base}')\n",
    "    tag, year_two = m.group(1).upper(), int(m.group(2))\n",
    "    year = 2000 + year_two\n",
    "    month = MONTHS[tag]\n",
    "    return datetime(year, month, 1)\n",
    "\n",
    "def rdp_indices(x, y, eps):\n",
    "    pts = np.column_stack([x, y])\n",
    "    n = len(pts)\n",
    "    if n <= 2:\n",
    "        return np.arange(n)\n",
    "\n",
    "    keep = np.zeros(n, dtype=bool)\n",
    "    keep[0] = True\n",
    "    keep[-1] = True\n",
    "    stack = [(0, n - 1)]\n",
    "\n",
    "    while stack:\n",
    "        i, j = stack.pop()\n",
    "        if j <= i + 1:\n",
    "            continue\n",
    "        a = pts[i]\n",
    "        b = pts[j]\n",
    "        ab = b - a\n",
    "        ab2 = ab @ ab\n",
    "        if ab2 == 0:\n",
    "            d = np.linalg.norm(pts[i + 1:j] - a, axis=1)\n",
    "        else:\n",
    "            ap = pts[i + 1:j] - a\n",
    "            t = (ap @ ab) / ab2\n",
    "            proj = a + np.outer(t, ab)\n",
    "            d = np.linalg.norm(pts[i + 1:j] - proj, axis=1)\n",
    "        k_rel = int(np.argmax(d))\n",
    "        dmax = float(d[k_rel]) if len(d) else 0.0\n",
    "        k = i + 1 + k_rel\n",
    "        if dmax > eps:\n",
    "            keep[k] = True\n",
    "            stack.append((i, k))\n",
    "            stack.append((k, j))\n",
    "    return np.where(keep)[0]\n",
    "\n",
    "def quarter_bounds(dt):\n",
    "    q = (dt.month - 1) // 3\n",
    "    start = datetime(dt.year, q * 3 + 1, 1)\n",
    "    end = start + relativedelta(months=3)\n",
    "    return start, end\n",
    "\n",
    "def avg_over_interval(x_s, y_s, start_x, end_x):\n",
    "    if start_x < x_s[0] or end_x > x_s[-1] or end_x <= start_x:\n",
    "        return np.nan\n",
    "    total = 0.0\n",
    "    for i in range(len(x_s) - 1):\n",
    "        seg_start = x_s[i]\n",
    "        seg_end = x_s[i + 1]\n",
    "        if seg_end <= start_x or seg_start >= end_x:\n",
    "            continue\n",
    "        a = max(start_x, seg_start)\n",
    "        b = min(end_x, seg_end)\n",
    "        y0 = y_s[i]\n",
    "        y1 = y_s[i + 1]\n",
    "        slope = (y1 - y0) / (seg_end - seg_start)\n",
    "        total += y0 * (b - a) + slope * 0.5 * ((b - seg_start) ** 2 - (a - seg_start) ** 2)\n",
    "    return total / (end_x - start_x)\n",
    "\n",
    "def fred_avg(start_dt, end_dt):\n",
    "    if end_dt < start_dt:\n",
    "        return np.nan\n",
    "    df = web.DataReader('DFF', 'fred', start_dt, end_dt)\n",
    "    return float(df['DFF'].mean()) if not df.empty else np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b681c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(path, H=12, x_round=3, eps=0.015):\n",
    "    raw = pd.read_csv(path, header=None, names=['x', 'y'])\n",
    "    raw = raw.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "    raw['x_bin'] = raw['x'].round(x_round)\n",
    "\n",
    "    def midline_agg(s):\n",
    "        spread = s.max() - s.min()\n",
    "        return s.min() if spread > 0.07 else s.median()\n",
    "\n",
    "    mid = raw.groupby('x_bin')['y'].apply(midline_agg).reset_index().rename(\n",
    "        columns={'x_bin': 'x', 'y': 'y_mid'}\n",
    "    ).sort_values('x')\n",
    "\n",
    "    x = mid['x'].to_numpy()\n",
    "    y = mid['y_mid'].to_numpy()\n",
    "    idx = rdp_indices(x, y, eps=eps)\n",
    "    x_s = x[idx]\n",
    "    y_s = y[idx]\n",
    "\n",
    "    forecast_date = parse_forecast_date_from_filename(path)\n",
    "    q_start, q_end = quarter_bounds(forecast_date)\n",
    "\n",
    "    prev_start = q_start - relativedelta(months=3)\n",
    "    prev_end = q_start - relativedelta(days=1)\n",
    "    lffr = fred_avg(prev_start, prev_end)\n",
    "\n",
    "    first_x = x_s[0]\n",
    "    last_x = x_s[-1]\n",
    "    first_dt = decimal_year_to_date(first_x)\n",
    "\n",
    "    out = {}\n",
    "    for h in range(H + 1):\n",
    "        start = q_start + relativedelta(months=3 * h)\n",
    "        end = q_start + relativedelta(months=3 * (h + 1))\n",
    "        start_x = date_to_decimal_year(start)\n",
    "        end_x = date_to_decimal_year(end)\n",
    "\n",
    "        if end_x > last_x:\n",
    "            out[f'ffr_{h}'] = np.nan\n",
    "            continue\n",
    "\n",
    "        if h == 0 and start_x < first_x < end_x:\n",
    "            fred_end = pd.Timestamp(first_dt).normalize()\n",
    "            dat = fred_avg(start, fred_end.to_pydatetime())\n",
    "            interp = avg_over_interval(x_s, y_s, first_x, end_x)\n",
    "            if np.isnan(dat) or np.isnan(interp):\n",
    "                out[f'ffr_{h}'] = np.nan\n",
    "                continue\n",
    "            q_prop = (first_x - start_x) / (end_x - start_x)\n",
    "            out[f'ffr_{h}'] = q_prop * dat + (1 - q_prop) * interp\n",
    "        else:\n",
    "            out[f'ffr_{h}'] = avg_over_interval(x_s, y_s, start_x, end_x)\n",
    "\n",
    "    out_row = {'Date': forecast_date}\n",
    "    out_row['lffr'] = lffr\n",
    "    out_row.update(out)\n",
    "    return out_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "716258f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>lffr</th>\n",
       "      <th>ffr_0</th>\n",
       "      <th>ffr_1</th>\n",
       "      <th>ffr_2</th>\n",
       "      <th>ffr_3</th>\n",
       "      <th>ffr_4</th>\n",
       "      <th>ffr_5</th>\n",
       "      <th>ffr_6</th>\n",
       "      <th>ffr_7</th>\n",
       "      <th>ffr_8</th>\n",
       "      <th>ffr_9</th>\n",
       "      <th>ffr_10</th>\n",
       "      <th>ffr_11</th>\n",
       "      <th>ffr_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0.101304</td>\n",
       "      <td>0.112704</td>\n",
       "      <td>0.186917</td>\n",
       "      <td>0.469325</td>\n",
       "      <td>0.820834</td>\n",
       "      <td>1.176844</td>\n",
       "      <td>1.501327</td>\n",
       "      <td>1.811605</td>\n",
       "      <td>2.126064</td>\n",
       "      <td>2.421171</td>\n",
       "      <td>2.704726</td>\n",
       "      <td>2.951103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>0.101304</td>\n",
       "      <td>0.125582</td>\n",
       "      <td>0.184167</td>\n",
       "      <td>0.403892</td>\n",
       "      <td>0.666044</td>\n",
       "      <td>0.954400</td>\n",
       "      <td>1.244722</td>\n",
       "      <td>1.505795</td>\n",
       "      <td>1.773618</td>\n",
       "      <td>2.004318</td>\n",
       "      <td>2.249474</td>\n",
       "      <td>2.478482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>0.112889</td>\n",
       "      <td>0.129791</td>\n",
       "      <td>0.165464</td>\n",
       "      <td>0.376902</td>\n",
       "      <td>0.646176</td>\n",
       "      <td>0.904903</td>\n",
       "      <td>1.133261</td>\n",
       "      <td>1.386009</td>\n",
       "      <td>1.611275</td>\n",
       "      <td>1.854972</td>\n",
       "      <td>2.076822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>0.112889</td>\n",
       "      <td>0.135438</td>\n",
       "      <td>0.163201</td>\n",
       "      <td>0.351262</td>\n",
       "      <td>0.590063</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>1.031571</td>\n",
       "      <td>1.263089</td>\n",
       "      <td>1.476983</td>\n",
       "      <td>1.691120</td>\n",
       "      <td>1.908482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>0.125604</td>\n",
       "      <td>0.169212</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.582795</td>\n",
       "      <td>0.804029</td>\n",
       "      <td>1.012605</td>\n",
       "      <td>1.244575</td>\n",
       "      <td>1.443000</td>\n",
       "      <td>1.640089</td>\n",
       "      <td>1.841454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      lffr     ffr_0     ffr_1     ffr_2     ffr_3     ffr_4  \\\n",
       "0 2015-01-01  0.101304  0.112704  0.186917  0.469325  0.820834  1.176844   \n",
       "1 2015-03-01  0.101304  0.125582  0.184167  0.403892  0.666044  0.954400   \n",
       "2 2015-04-01  0.112889  0.129791  0.165464  0.376902  0.646176  0.904903   \n",
       "3 2015-06-01  0.112889  0.135438  0.163201  0.351262  0.590063  0.824719   \n",
       "4 2015-07-01  0.125604  0.169212  0.347553  0.582795  0.804029  1.012605   \n",
       "\n",
       "      ffr_5     ffr_6     ffr_7     ffr_8     ffr_9    ffr_10  ffr_11  ffr_12  \n",
       "0  1.501327  1.811605  2.126064  2.421171  2.704726  2.951103     NaN     NaN  \n",
       "1  1.244722  1.505795  1.773618  2.004318  2.249474  2.478482     NaN     NaN  \n",
       "2  1.133261  1.386009  1.611275  1.854972  2.076822       NaN     NaN     NaN  \n",
       "3  1.031571  1.263089  1.476983  1.691120  1.908482       NaN     NaN     NaN  \n",
       "4  1.244575  1.443000  1.640089  1.841454       NaN       NaN     NaN     NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = 12\n",
    "rows = []\n",
    "pattern = re.compile(r'^[A-Za-z]{3}\\d{2}FFR\\.csv$')\n",
    "for path in sorted(glob.glob('*.csv')):\n",
    "    if not pattern.match(path):\n",
    "        continue\n",
    "    rows.append(process_csv(path, H=H))\n",
    "\n",
    "df_out = pd.DataFrame(rows).sort_values('Date').reset_index(drop=True)\n",
    "df_out = df_out.dropna(axis=1, how='all')\n",
    "\n",
    "df_out.to_csv('ffr_quarterly_forecasts.csv', index=False)\n",
    "df_out.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "481743af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APR15FFR.csv: max |y diff| = 0.0303664045507777 at x = 2015.30089283622\n",
      "APR16FFR.csv: max |y diff| = 0.06149024922184321 at x = 2017.311813157728\n",
      "APR17FFR.csv: max |y diff| = 0.05663144319174673 at x = 2018.4996903811752\n",
      "APR18FFR.csv: max |y diff| = 0.05993808049535598 at x = 2018.613074792244\n",
      "APR19FFR.csv: max |y diff| = 0.022937905468026543 at x = 2021.2884615384612\n",
      "DEC15FFR.csv: max |y diff| = 0.030180208268379083 at x = 2015.8881600229088\n",
      "DEC16FFR.csv: max |y diff| = 0.05703959773727174 at x = 2017.1764386395964\n",
      "DEC17FFR.csv: max |y diff| = 0.03036640455077899 at x = 2018.3420603723207\n",
      "DEC18FFR.csv: max |y diff| = 0.09855889724310796 at x = 2019.0252155813264\n",
      "DEC19FFR.csv: max |y diff| = 0.022652577276698338 at x = 2022.5581794361945\n",
      "JAN16FFR.csv: max |y diff| = 0.056543230389000776 at x = 2016.3754860093056\n",
      "JAN17FFR.csv: max |y diff| = 0.0609520611199732 at x = 2017.601100223483\n",
      "JAN18FFR.csv: max |y diff| = 0.057889919707117654 at x = 2018.439283694977\n",
      "JAN19FFR.csv: max |y diff| = 0.0606414968259279 at x = 2019.8305487370335\n",
      "JUL15FFR.csv: max |y diff| = 0.030180208268379083 at x = 2017.5929762343676\n",
      "JUL16FFR.csv: max |y diff| = 0.11070797576981395 at x = 2017.6480533679824\n",
      "JUL17FFR.csv: max |y diff| = 0.06040687273786216 at x = 2017.753921838448\n",
      "JUL18FFR.csv: max |y diff| = 0.060848611838660194 at x = 2019.7722109158185\n",
      "JUL19FFR.csv: max |y diff| = 0.02296015180265698 at x = 2020.6177152022813\n",
      "JUN15FFR.csv: max |y diff| = 0.07545208896279387 at x = 2016.2824690520208\n",
      "JUN16FFR.csv: max |y diff| = 0.026548949952983403 at x = 2017.8793538777688\n",
      "JUN17FFR.csv: max |y diff| = 0.05703959773727174 at x = 2018.18719772404\n",
      "JUN18FFR.csv: max |y diff| = 0.11412223340040217 at x = 2018.850859081189\n",
      "JUN19FFR.csv: max |y diff| = 0.030372756557754066 at x = 2020.936375603335\n",
      "MAR15FFR.csv: max |y diff| = 0.03037911122269671 at x = 2015.577249823377\n",
      "MAR16FFR.csv: max |y diff| = 0.0837528316133902 at x = 2016.238011373281\n",
      "MAR17FFR.csv: max |y diff| = 0.08324993745308973 at x = 2018.1769856804367\n",
      "MAR18FFR.csv: max |y diff| = 0.0614057345851311 at x = 2020.042766820972\n",
      "MAR19FFR.csv: max |y diff| = 0.12888471177944938 at x = 2019.2642344497608\n",
      "OCT15FFR.csv: max |y diff| = 0.02668669131238488 at x = 2016.5946962274045\n",
      "OCT16FFR.csv: max |y diff| = 0.08335768861425308 at x = 2018.56083942515\n",
      "OCT17FFR.csv: max |y diff| = 0.11395027624309328 at x = 2018.7678999944196\n",
      "OCT18FFR.csv: max |y diff| = 0.10689045936395747 at x = 2020.3742189215627\n",
      "OCT19FFR.csv: max |y diff| = 0.025292642140468002 at x = 2019.8705242966755\n",
      "SEP15FFR.csv: max |y diff| = 0.030540131246844737 at x = 2015.7430663243256\n",
      "SEP16FFR.csv: max |y diff| = 0.06847334004024086 at x = 2019.3227354322007\n",
      "SEP17FFR.csv: max |y diff| = 0.0767214777867018 at x = 2018.8062169250877\n",
      "SEP18FFR.csv: max |y diff| = 0.15949033391915624 at x = 2018.7309781259617\n",
      "SEP19FFR.csv: max |y diff| = 0.015165441176471006 at x = 2021.0676031606672\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate x values and report max |y diff| per file\n",
    "for path in sorted(glob.glob('*.csv')):\n",
    "    df = pd.read_csv(path, header=None, names=['x', 'y']).apply(pd.to_numeric, errors='coerce').dropna()\n",
    "    dup = df[df.duplicated(subset=['x'], keep=False)]\n",
    "    if dup.empty:\n",
    "        continue\n",
    "    diff_by_x = dup.groupby('x')['y'].agg(lambda s: s.max() - s.min())\n",
    "    max_x = diff_by_x.idxmax()\n",
    "    max_diff = diff_by_x.loc[max_x]\n",
    "    print(f\"{path}: max |y diff| = {max_diff} at x = {max_x}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fresh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
